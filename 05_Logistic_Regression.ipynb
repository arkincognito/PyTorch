{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7HNC8deH4//07U7cxy4fY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkincognito/PyTorch/blob/main/05_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPd35PXAsZUU"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Let X, W, and b to be matrices of $[m, d]$, $[d,1]$, $[1,1]$.<br>\n",
        "For classification problems, y is a matrix of the class labels.<br>\n",
        "To begin with, let's consider simple binary classification problem.<br>\n",
        "y will be a matrix of $[m,1]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHe6FsQXvEUK"
      },
      "source": [
        "# Hypothesis\n",
        "For Single layer logistic regression model,<br>\n",
        "Hypothesis:<br>\n",
        "$$H(x^{(i)}) = {1\\over 1 + e^{-f(x^{(i)})}}$$<br>\n",
        "where <br>\n",
        "\n",
        "$$f(x^{(i)}) = x^{(i)} \\times W + b$$<br>\n",
        "\n",
        "$H(x^{(i)})$ is in the form of Sigmoid function, which can also be interpreted as<br><br>\n",
        "$$H(x^{(i)}) \\approx P(y^{(i)}=1; W) = 1- P(y^{(i)} = 0; W)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCqkOA3E0Bz0"
      },
      "source": [
        "# Cost \n",
        "Binary Cross Entropy:\n",
        "$$Cost = - {1\\over m} \\sum _{i=1} ^m ylog(H(x^{(i)}) + (1-y)log(H(x^{(i)}))$$<br>\n",
        "If the $Cost\\approx0$, then $y^{(i)}\\approx H(x^{(i)})$<br>\n",
        "and if the cost is high, then $y^{(i)}\\not= H(x^{(i)})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAhycZRe1a4j"
      },
      "source": [
        "# Update by Gradient Descent\n",
        "\n",
        "$$W := W - lr {\\partial\\over \\partial W}Cost(W) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsnwwFJi4-KC"
      },
      "source": [
        "# Logistic Regression from Scrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3XImXvX5CkY"
      },
      "source": [
        "Let's import files to build logistic regression model, and set seed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q3LWsXksT0r",
        "outputId": "1a02fb6b-0e51-45be-8d3c-8647b5d3e6f3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#For reproducibility\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5e140edb28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsc6hltY5Lo_"
      },
      "source": [
        "Let's make a dataset. We could pretend x are the hours working on the course's homework and hours studying by them selves, and y are whether the student has failed the course or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrShnqxb24jq",
        "outputId": "b2bbd25d-8129-49b7-9bca-42bf27a9a785"
      },
      "source": [
        "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "print(x_train, '\\n', y_train)\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [2., 3.],\n",
            "        [3., 1.],\n",
            "        [4., 3.],\n",
            "        [5., 3.],\n",
            "        [6., 2.]]) \n",
            " tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "torch.Size([6, 2]) torch.Size([6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOXJxWPU5wzI"
      },
      "source": [
        "Set the weights and bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvmYe2QD3XlQ"
      },
      "source": [
        "W = torch.zeros((2,1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdMWCVrL50Z1"
      },
      "source": [
        "Let's see the hypothesis values at the initial state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMi8uVt239M4",
        "outputId": "2a48ffd3-2938-457f-8d48-fb5283632caf"
      },
      "source": [
        "hypothesis = 1/(1 + torch.exp(-x_train.mm(W)+b))\n",
        "print(hypothesis)\n",
        "print(hypothesis.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<MulBackward0>)\n",
            "torch.Size([6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZOII5kO4os9"
      },
      "source": [
        "We could use ```torch.sigmoid()``` instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuyMzZhB4RqE",
        "outputId": "83ab05f1-c71b-4f20-e4db-8474e7cf0c41"
      },
      "source": [
        "hypothesis = torch.sigmoid(x_train.mm(W)+b)\n",
        "print(hypothesis)\n",
        "print(hypothesis.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward>)\n",
            "torch.Size([6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LmRLroP4zrI",
        "outputId": "1860ab0b-ee20-4db5-cadd-0c1bdfb0d6a2"
      },
      "source": [
        "cost = -(y_train*torch.log(hypothesis) + (1-y_train)*torch.log(hypothesis)).mean()\n",
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6931, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS8GmdhI6v59"
      },
      "source": [
        "This is the Binary Cross Entropy, and we can use ```F.binary_cross_entropy()``` to simplify the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTwsgLvC6S6W",
        "outputId": "049ba842-ead7-4b6a-99c8-396519d4fa89"
      },
      "source": [
        "cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBlfkgQh7Goz",
        "outputId": "4f579288-faf8-40f4-dcd2-20d4432b7152"
      },
      "source": [
        "\n",
        "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "W = torch.zeros((2,1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD([W, b], lr = 1)\n",
        "nb_epoch = 1000\n",
        "for epoch in range(nb_epoch+1):\n",
        "  # Calculate H(x)\n",
        "  hypothesis = torch.sigmoid(x_train.mm(W)+b)\n",
        "  # Calculate cost\n",
        "  cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "  \n",
        "  # Initialize all the gradients to zero\n",
        "  optimizer.zero_grad()\n",
        "  # Backward Propagation\n",
        "  cost.backward()\n",
        "  # Update\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'Epoch: {epoch:4d}\\t|hypothesis: {hypothesis.squeeze().detach()}\\t|cost: {cost.item():.4f}')\n",
        "print('train finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0\t|hypothesis: tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000])\t|cost: 0.6931\n",
            "Epoch:  100\t|hypothesis: tensor([0.0245, 0.1484, 0.2770, 0.7954, 0.9484, 0.9834])\t|cost: 0.1347\n",
            "Epoch:  200\t|hypothesis: tensor([0.0080, 0.1065, 0.1632, 0.8566, 0.9769, 0.9931])\t|cost: 0.0806\n",
            "Epoch:  300\t|hypothesis: tensor([0.0037, 0.0822, 0.1161, 0.8888, 0.9869, 0.9965])\t|cost: 0.0579\n",
            "Epoch:  400\t|hypothesis: tensor([0.0021, 0.0669, 0.0902, 0.9090, 0.9916, 0.9979])\t|cost: 0.0453\n",
            "Epoch:  500\t|hypothesis: tensor([0.0013, 0.0564, 0.0739, 0.9229, 0.9941, 0.9986])\t|cost: 0.0373\n",
            "Epoch:  600\t|hypothesis: tensor([8.7256e-04, 4.8759e-02, 6.2629e-02, 9.3312e-01, 9.9567e-01, 9.9906e-01])\t|cost: 0.0317\n",
            "Epoch:  700\t|hypothesis: tensor([6.2087e-04, 4.2945e-02, 5.4368e-02, 9.4091e-01, 9.9668e-01, 9.9932e-01])\t|cost: 0.0276\n",
            "Epoch:  800\t|hypothesis: tensor([4.6039e-04, 3.8371e-02, 4.8050e-02, 9.4706e-01, 9.9737e-01, 9.9949e-01])\t|cost: 0.0244\n",
            "Epoch:  900\t|hypothesis: tensor([3.5258e-04, 3.4679e-02, 4.3059e-02, 9.5205e-01, 9.9786e-01, 9.9961e-01])\t|cost: 0.0219\n",
            "Epoch: 1000\t|hypothesis: tensor([2.7711e-04, 3.1636e-02, 3.9014e-02, 9.5618e-01, 9.9823e-01, 9.9969e-01])\t|cost: 0.0199\n",
            "train finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-lqJQ4o7vf9",
        "outputId": "568d2928-91f9-4385-e024-c6749e0c3e15"
      },
      "source": [
        "prediction = hypothesis >= 0.5\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [ True],\n",
            "        [ True]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qv2ac3J9Fxe",
        "outputId": "e1a93081-e749-4ecb-d0ab-14a371b9f625"
      },
      "source": [
        "accuracy = (prediction == y_train).float().mean()\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL2R3MTbAuB8"
      },
      "source": [
        "Let's try this with larger dataset with 8 parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq5raT2zBAaa"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgSHDKGgA0IF"
      },
      "source": [
        "xy = np.loadtxt('https://raw.githubusercontent.com/deeplearningzerotoall/PyTorch/master/data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa5CuIyc-umd"
      },
      "source": [
        "# Implementing nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1-vq8U_99HG"
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(8,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.sigmoid(self.linear(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLWt-Aus_he0",
        "outputId": "5bd95e50-e685-4332-cf30-285f16834b04"
      },
      "source": [
        "model = BinaryClassifier()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
        "nb_epoch = 100\n",
        "for epoch in range(nb_epoch+1):\n",
        "  # Calculate H(x)\n",
        "  hypothesis = model(x_train)\n",
        "  # Calculate cost\n",
        "  cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "  # Update Weights and Bias\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 10 == 0:\n",
        "    prediction = hypothesis >= 0.5\n",
        "    accuracy = (prediction == y_train).float().mean()\n",
        "    print(f'Epoch: {epoch:4d}\\t|accuracy: {accuracy * 100:.2f}%\\t|cost: {cost.item():.4f}')\n",
        "print('train finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0\t|accuracy: 40.18%\t|cost: 0.7176\n",
            "Epoch:   10\t|accuracy: 66.14%\t|cost: 0.5884\n",
            "Epoch:   20\t|accuracy: 70.88%\t|cost: 0.5501\n",
            "Epoch:   30\t|accuracy: 75.10%\t|cost: 0.5269\n",
            "Epoch:   40\t|accuracy: 76.68%\t|cost: 0.5121\n",
            "Epoch:   50\t|accuracy: 77.34%\t|cost: 0.5021\n",
            "Epoch:   60\t|accuracy: 77.21%\t|cost: 0.4951\n",
            "Epoch:   70\t|accuracy: 77.34%\t|cost: 0.4901\n",
            "Epoch:   80\t|accuracy: 77.21%\t|cost: 0.4864\n",
            "Epoch:   90\t|accuracy: 76.81%\t|cost: 0.4837\n",
            "Epoch:  100\t|accuracy: 76.81%\t|cost: 0.4815\n",
            "train finished\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}